# -*- coding: utf-8 -*-
"""loan_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DR3VE8wa-FIcHL4N2w_1dvSb66y25xty

# Loan Prediction
"""


# pip install catboost

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

import joblib
import pandas as pd
import numpy as np
from lightgbm import LGBMClassifier
import xgboost as xgb
#import mlflow
import mlflow.sklearn

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_validate, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss
from catboost import CatBoostClassifier
import lightgbm as lgb
from sklearn.model_selection import RandomizedSearchCV


from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import accuracy_score
from sklearn.utils import class_weight


from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import classification_report
from matplotlib import pyplot as plt





"""# Functions"""

def check_df(dataframe, head=5):
    print("##################### Shape #####################")
    print(dataframe.shape)
    print("##################### Types #####################")
    print(dataframe.dtypes)
    print("##################### Head #####################")
    print(dataframe.head(head))
    #print("##################### Tail #####################")
    # print(dataframe.tail(head))
    print("##################### NA #####################")
    print(dataframe.isnull().sum())
    print("##################### Quantiles #####################")
    print(dataframe.describe([0, 0.05, 0.50, 0.95, 0.99, 1]).T)


def grab_col_names(dataframe, cat_th=10, car_th=20):
    # cat_cols, cat_but_car
    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and
                   dataframe[col].dtypes != "O"]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and
                   dataframe[col].dtypes == "O"]
    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    # num_cols
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
    num_cols = [col for col in num_cols if col not in num_but_cat]

    # print(f"Observations: {dataframe.shape[0]}")
    # print(f"Variables: {dataframe.shape[1]}")
    # print(f'cat_cols: {len(cat_cols)}')
    # print(f'num_cols: {len(num_cols)}')
    # print(f'cat_but_car: {len(cat_but_car)}')
    # print(f'num_but_cat: {len(num_but_cat)}')
    return cat_cols, num_cols, cat_but_car


def target_vs_category_visual(dataframe, target, categorical_col):
    plt.figure(figsize=(15, 8))
    sns.histplot(x=target, hue=categorical_col, data=dataframe, element="step", multiple="dodge")
    plt.title("State of Categorical Variables according to Churn ")
    plt.show()

def cat_summary(dataframe, col_name, plot=False):
    if plot:
        sns.countplot(x=dataframe[col_name], data=dataframe)
        plt.show(block=True)
        print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),
                            "Ratio": 100 * dataframe[col_name].value_counts() / len(dataframe)}))
        print("##########################################")


def target_summary_with_cat(dataframe, target, categorical_col):
    print(pd.DataFrame({"LOAN STATUS": dataframe.groupby(categorical_col)[target].mean()}))
    print(20 * "-")


def target_summary_with_num(dataframe, target, numerical_col):
    print(dataframe.groupby(target).agg({numerical_col: "mean"}), end="\n\n")
    print("###################################")


def get_numerical_summary(dataframe):
    total = df.shape[0]
    missing_columns = [col for col in df.columns if df[col].isnull().sum() > 0]
    missing_percent = {}
    for col in missing_columns:
        null_count = df[col].isnull().sum()
        per = (null_count / total) * 100
        missing_percent[col] = per
        print("{} : {} ({}%)".format(col, null_count, round(per, 3)))
    return missing_percent





def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):
    quartile1 = dataframe[col_name].quantile(q1)
    quartile3 = dataframe[col_name].quantile(q3)
    interquantile_range = quartile3 - quartile1
    up_limit = quartile3 + 1.5 * interquantile_range
    low_limit = quartile1 - 1.5 * interquantile_range
    return low_limit, up_limit


def missing_values_table(dataframe, na_name=False):
    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]

    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)
    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)
    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])
    print(missing_df, end="\n")

    if na_name:
        return na_columns


def missing_vs_target(dataframe, target, na_columns):
    temp_df = dataframe.copy()
    for col in na_columns:
        temp_df[col + '_NA_FLAG'] = np.where(temp_df[col].isnull(), 1, 0)

    na_flags = temp_df.loc[:, temp_df.columns.str.contains("_NA_")].columns

    for col in na_flags:
        print(pd.DataFrame({"TARGET_MEAN": temp_df.groupby(col)[target].mean(),
                            "Count": temp_df.groupby(col)[target].count()}), end="\n\n\n")


def quick_missing_imp(dataframe, target, num_method="median", cat_length=20):
    variables_with_na = [col for col in dataframe.columns if
                         dataframe[col].isnull().sum() > 0]  # Eksik değere sahip olan değişkenler listelenir

    temp_target = dataframe[target]

    print("# BEFORE")
    print(dataframe[variables_with_na].isnull().sum(),
          "\n\n")  # Uygulama öncesi değişkenlerin eksik değerlerinin sayısı

    # değişken object ve sınıf sayısı cat_lengthe eşit veya altındaysa boş değerleri mode ile doldur
    dataframe = dataframe.apply(
        lambda x: x.fillna(x.mode()[0]) if (x.dtype == "O" and len(x.unique()) <= cat_length) else x, axis=0)

    # num_method mean ise tipi object olmayan değişkenlerin boş değerleri ortalama ile dolduruluyor
    if num_method == "mean":
        dataframe = dataframe.apply(lambda x: x.fillna(x.mean()) if x.dtype != "O" else x, axis=0)
    # num_method median ise tipi object olmayan değişkenlerin boş değerleri ortalama ile dolduruluyor
    elif num_method == "median":
        dataframe = dataframe.apply(lambda x: x.fillna(x.median()) if x.dtype != "O" else x, axis=0)

    dataframe[target] = temp_target

    print("# AFTER \n Imputation method is 'MODE' for categorical variables!")
    print(" Imputation method is '" + num_method.upper() + "' for numeric variables! \n")
    print(dataframe[variables_with_na].isnull().sum(), "\n\n")

    return dataframe


def outlier_th(dataframe, col_name, q1=0.05, q3=0.95):
    quartile1 = dataframe[col_name].quantile(q1)
    quartile3 = dataframe[col_name].quantile(q3)
    interquantile_range = quartile3 - quartile1
    up_limit = quartile3 + 1.5 * interquantile_range
    low_limit = quartile1 - 1.5 * interquantile_range
    return low_limit, up_limit

# Define a Function about checking outlier for data columns
def check_outlier(dataframe, col_name):
    low_limit, up_limit = outlier_th(dataframe, col_name)
    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):
        return True
    else:
        return False

# Define a Function about replace with threshold for data columns
def replace_with_thresholds(dataframe, variable):
    low_limit, up_limit = outlier_th(dataframe, variable)
    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit
    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit


def missing_values_table(dataframe, na_name=False):
    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]

    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)
    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)
    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])
    print(missing_df, end="\n")

    if na_name:
        return na_columns


def one_hot_encoder(dataframe, categorical_cols, drop_first=False):
    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)
    return dataframe



def train_test(X, y, test_size=0.20):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

    print("Base Models....")
    classifiers = [  #('LR', LogisticRegression()),
        # ('KNN', KNeighborsClassifier()),
        # ("SVC", SVC()),
        ("CART", DecisionTreeClassifier(random_state=0)),
        ("RF", RandomForestClassifier(random_state=0, max_features='sqrt')),
        # ('Adaboost', AdaBoostClassifier(random_state=0)),
         ('GBM', GradientBoostingClassifier(max_depth=4,random_state=0)),
        ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),
        ('LightGBM', LGBMClassifier(random_state=0, verbose=-1)),
        ('CatBoost', CatBoostClassifier(verbose=False))
    ]
    print(classifiers)
    return X_train, X_test, y_train, y_test, classifiers

def models(classfiers, X, y):
    for name, classifier in classifiers:
        classifier.fit(X_train, y_train)
        prediction = classifier.predict(X_test)

        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)
        # Calculating Cross-Validation scores for different metrics
        accuracy_cv = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='accuracy',n_jobs=-1).mean()
        f1_cv = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='f1',n_jobs=-1).mean()
        precision_cv = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='precision',n_jobs=-1).mean()
        recall_cv = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='recall',n_jobs=-1).mean()

        # Printing Cross-Validation scores
        print(f"Classifier: {name}")
        print("Cross Validation Scores:")
        print("Accuracy : ", '{0:.2%}'.format(accuracy_cv))
        print("F1 : ", '{0:.2%}'.format(f1_cv))
        print("Precision : ", '{0:.2%}'.format(precision_cv))
        print("Recall : ", '{0:.2%}'.format(recall_cv))

        # Accuracy on test data
        test_accuracy = accuracy_score(y_test, prediction)
        print("Test Accuracy : ", '{0:.2%}'.format(test_accuracy))


def model_evaluation(classifiers, X_test, y_test, X_train, y_train):
    for name, classifier in classifiers:
        classifier.fit(X_train, y_train)
        cm = confusion_matrix(y_test, classifier.predict(X_test))
        names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']
        counts = [value for value in cm.flatten()]
        percentages = ['{0:.2%}'.format(value) for value in cm.flatten() / np.sum(cm)]
        labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in zip(names, counts, percentages)]
        labels = np.asarray(labels).reshape(2, 2)

        # Her sınıflandırıcı için ayrı bir grafik çiz
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=labels, cmap='Blues', fmt='', square=True)
        plt.title(f'Confusion Matrix for {name}')
        plt.ylabel('True label')
        plt.xlabel('Predicted label')

        # Göster
        plt.show(block=True)

        # Sınıflandırma raporunu yazdır
        print(f'Classification Report for {name}:\n')
        print(classification_report(y_test, classifier.predict(X_test)))


def feature_importances(classifiers, X, y,count=15):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

    for name, classifier in classifiers:
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_test)
        acc_score = accuracy_score(y_test, y_pred)
        feature_imp = pd.Series(classifier.feature_importances_,
                                index=X.columns).sort_values(ascending=False)[:count]

        sns.barplot(x=feature_imp, y=feature_imp.index)
        plt.xlabel('Değişken Önem Skorları')
        plt.ylabel('Değişkenler')
        plt.title(name)
        plt.show(block=True)


def hyperparameter_optimization(X, y, classifiers, cv=5, main_scoring='accuracy'):
    print("Hyperparameter Optimization....")
    best_models = {}
    scoring_metrics = ['accuracy', 'f1', 'recall', 'precision']

    for name, classifier, params in classifiers:
        print(f"########## {name} ##########")

        initial_scores = {}
        for metric in scoring_metrics:
            cv_results = cross_validate(classifier, X, y, cv=cv, scoring=metric)
            mean_score = round(cv_results['test_score'].mean(), 4)
            initial_scores[metric] = mean_score
            print(f"{metric} (Before): {mean_score}")

        # GridSearchCV ile hiperparametre optimizasyonu
        # RandomSearchCV
        gs_best = RandomizedSearchCV(classifier, params, cv=cv, scoring=main_scoring, n_jobs=-1, verbose=False).fit(X, y)
        final_model = classifier.set_params(**gs_best.best_params_)
        print(f"{name} best params: {gs_best.best_params_}")

        # Optimizasyon sonrası skorları hesaplama
        optimized_scores = {}
        for metric in scoring_metrics:
            cv_results = cross_validate(final_model, X, y, cv=cv, scoring=metric)
            mean_score = round(cv_results['test_score'].mean(), 4)
            optimized_scores[metric] = mean_score
            print(f"{metric} (After): {mean_score}")

        best_models[name] = {
            'final_model': final_model,
            'initial_scores': initial_scores,
            'optimized_scores': optimized_scores
        }

    return best_models





"""# Reading Dataset"""

from google.colab import drive
drive.mount('/content/drive')

loan_train = pd.read_csv("/content/drive/MyDrive/loan_dataset/train.csv")
loan_test = pd.read_csv("/content/drive/MyDrive/loan_dataset/test.csv")



df = pd.concat([loan_train, loan_test], ignore_index=True)
df.head()





"""# Exploratory Data Analysis"""

check_df(df)

df.describe([0.25,0.5,0.7,0.8,0.85,0.9,0.95,0.99]).T



df['loan_status'].value_counts()



"""# Summarize for Categorical Columns"""

cat_cols, num_cols, cat_but_car = grab_col_names(df)



for col in cat_cols:
    cat_summary(df, col,plot=True)





for col in cat_cols:
    target_summary_with_cat(df,"loan_status",col)

"""# Notes"""



"""* Person_Home_Ownership degiskeninde Rent bilgisini tasiyanlarin Loan olma durumu daha yüksek

*   Loan Grade degeri D, E, F ve G bilgisini tasiyanlarin Loan olma durumu yüksek.
*   Loan_Intent degiskenine göre DebtConsolidation, Home Improvement ve Medical olanlarin Loan olma sinifi daha belirgin.

# Summarize for Numerical Columns
"""



for col in num_cols:
    target_summary_with_num(df,"loan_status",col)

"""# Notes

*   Person Income degeri düsük olanlarin Loan olma durumu daha yüksek.
*   Loan_Int_Rate ortalama 13 civarinda olanlarin Loan olma durumu yüksek.


"""





"""# Correlation"""

plt.figure(figsize = (20,5))
sns.heatmap(df[num_cols].corr(),annot = True);

corr_matrix = df[num_cols].corr()
corr_matrix



"""# Data Visualization"""

# @title person_age

from matplotlib import pyplot as plt
df['person_age'].plot(kind='hist', bins=20, title='person_age')
plt.gca().spines[['top', 'right',]].set_visible(False)



# @title person_income

from matplotlib import pyplot as plt
df['person_income'].plot(kind='hist', bins=20, title='person_income')
plt.gca().spines[['top', 'right',]].set_visible(False)



# @title loan_amount

from matplotlib import pyplot as plt
df['loan_amnt'].plot(kind='hist', bins=20, title='loan_amount')
plt.gca().spines[['top', 'right',]].set_visible(False)



# @title person_age vs person_income

from matplotlib import pyplot as plt
df.plot(kind='scatter', x='person_age', y='person_income', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)



# @title person_income vs loan_amount

from matplotlib import pyplot as plt
df.plot(kind='scatter', x='person_income', y='loan_amnt', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

cat_cols



# @title loan_intent

from matplotlib import pyplot as plt
import seaborn as sns
df.groupby('loan_intent').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)



# @title person_hole_ownership

from matplotlib import pyplot as plt
import seaborn as sns
df.groupby('person_home_ownership').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)



# @title loan_grade

from matplotlib import pyplot as plt
import seaborn as sns
df.groupby('loan_grade').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)



# @title person_home_ownership vs loan_intent

from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['loan_intent'].value_counts()
    for x_label, grp in df.groupby('person_home_ownership')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('person_home_ownership')
_ = plt.ylabel('loan_intent')



# @title loan_grade vs cb_person_default_on_file

from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['cb_person_default_on_file'].value_counts()
    for x_label, grp in df.groupby('loan_grade')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('loan_grade')
_ = plt.ylabel('cb_person_default_on_file')



# @title id vs person_age

from matplotlib import pyplot as plt
import seaborn as sns
def _plot_series(series, series_name, series_index=0):
  palette = list(sns.palettes.mpl_palette('Dark2'))
  xs = series['id']
  ys = series['person_age']

  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])

fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
df_sorted = df.sort_values('id', ascending=True)
for i, (series_name, series) in enumerate(df_sorted.groupby('loan_grade')):
  _plot_series(series, series_name, i)
  fig.legend(title='loan_grade', bbox_to_anchor=(1, 1), loc='upper left')
sns.despine(fig=fig, ax=ax)
plt.xlabel('id')
_ = plt.ylabel('person_age')









"""# Data Preparation"""

missing_values_table(df)

df.isnull().sum()



num_cols



for col in num_cols:
    print(col, check_outlier(df, col))

for col in num_cols:
    replace_with_thresholds(df, col)

for col in num_cols:
    print(col, check_outlier(df, col))





"""# Encoding"""

binary_cols = [col for col in df.columns if df[col].dtype not in [int, float]
               and df[col].nunique() == 2]

binary_cols

ohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]

df = one_hot_encoder(df, ohe_cols)



scaler = RobustScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

df[num_cols].head()



cat_cols, num_cols, cat_but_car = grab_col_names(df)

df.head()



"""# Modeling"""

df1 = df[df['loan_status'].notnull()]

df1.isnull().sum()

df1.head()

y = df1["loan_status"]
X = df1.drop(["loan_status","cb_person_default_on_file"], axis=1)



X_train, X_test, y_train, y_test,classifiers = train_test(X,y)



# Model success evaluation with Hold-Out via the complexity matrix
model_evaluation(classifiers,X_test,y_test,X_train,y_train)





# Model success evaluation with K-Fold Cross Validation
models(classifiers,X,y)



feature_importances(classifiers,X,y,count=15)







"""# Hyperparameter Optimization"""

cart_params = {'max_depth': range(1, 20),
               "min_samples_split": range(2, 30) }

rf_params = {"max_depth": [8, 15, None],
             "max_features": [5, 7, "sqrt"],
             "min_samples_split": [15, 20],
             "n_estimators": [200, 300,500]}

xgboost_params = {"learning_rate": [0.1, 0.01],
                  "max_depth": [5, 8],
                  "n_estimators": [100,200,500],
                  "colsample_bytree": [0.5, 1],}

lightgbm_params = {"learning_rate": [0.01, 0.1],
                   "n_estimators": [300, 500,1000],
                   "colsample_bytree": [0.7, 1]}

catboost_params = {
    'learning_rate': [0.01, 0.05, 0.1, 0.3],
    'depth': [4, 6, 8, 10],
    'iterations': [100, 250, 500, 1000],
    'l2_leaf_reg': [1, 3, 5, 7, 9],
    'border_count': [32, 64, 128, 255],
    'bagging_temperature': [0.0, 0.5, 1.0],
    'auto_class_weights': ['None', 'Balanced', 'SqrtBalanced']
}

classifiers = [#('KNN', KNeighborsClassifier(), knn_params),
               ("CART", DecisionTreeClassifier(random_state=42), cart_params),
               ("RF", RandomForestClassifier(random_state=42), rf_params),
               ('XGBoost', xgb.XGBClassifier(eval_metric='logloss',random_state=42), xgboost_params),
               ('LightGBM', LGBMClassifier(random_state=42,verbose=-1), lightgbm_params),
                ('CatBoost', CatBoostClassifier(verbose=False),catboost_params)]



#best_models = hyperparameter_optimization(X,y,classifiers)







"""# Optimization Result"""

# model_results_df = pd.DataFrame(columns=['Model', 'Metric', 'Before Optimization', 'After Optimization'])

# for name, model_info in best_models.items():
#    for metric in model_info['initial_scores']:
#        before_score = model_info['initial_scores'][metric]
#        after_score = model_info['optimized_scores'][metric]
#        model_results_df = model_results_df.append({
#            'Model': name,
#            'Metric': metric,
#            'Before Optimization': before_score,
#            'After Optimization': after_score
#        }, ignore_index=True)

# print(model_results_df)

